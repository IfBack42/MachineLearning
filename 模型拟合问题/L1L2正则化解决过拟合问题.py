"""
æ¼”ç¤º æ¬ æ‹Ÿåˆ æ­£å¥½æ‹Ÿåˆ è¿‡æ‹Ÿåˆ L1æ­£åˆ™åŒ– L3æ­£åˆ™åŒ– æ•ˆæœå›¾

æ¬ æ‹Ÿåˆï¼šæ¨¡å‹åœ¨è®­ç»ƒé›†å’Œæµ‹è¯•é›†è¡¨ç°éƒ½ä¸å¥½ -> å¢åŠ ç‰¹å¾ï¼Œæé«˜æ¨¡å‹å¤æ‚åº¦
æ­£å¥½æ‹Ÿåˆï¼šæ¨¡å‹åœ¨è®­ç»ƒé›†å’Œæµ‹è¯•é›†è¡¨ç°éƒ½å¥½
è¿‡æ‹Ÿåˆï¼š æ¨¡å‹åœ¨è®­ç»ƒé›†è¡¨è¡¨ç°å¥½ï¼Œåœ¨æµ‹è¯•é›†è¡¨ç°ä¸å¥½

æ¬ æ‹ŸåˆåŸå› ï¼š
    å­¦ä¹ åˆ°æ•°æ®ç‰¹å¾è¿‡å°‘
è§£å†³ï¼š ä»æ•°æ®ã€æ¨¡å‹ã€ç®—æ³•è§’åº¦è§£å†³
    1.æ·»åŠ å…¶ä»–ç‰¹å¾
    2.â€œç»„åˆâ€â€œæ³›åŒ–â€â€œç›¸å…³æ€§â€ç‰¹å¾
    3.æ·»åŠ å¤šé¡¹å¼ç‰¹å¾

è¿‡æ‹ŸåˆåŸå› ï¼š
    åŸå§‹ç‰¹å¾è¿‡å¤šï¼Œå­˜åœ¨å˜ˆæ‚ç‰¹å¾ï¼Œæ¨¡å‹å…¼é¡¾å¤ªå¤šæ•°æ®ç‚¹å¯¼è‡´æ¨¡å‹å¤æ‚
è§£å†³ï¼š
    1.é‡æ–°æ¸…æ´—æ•°æ®ï¼Œå¯¹è¿‡å¤šå¼‚å¸¸ç‚¹æ•°æ®ã€ä¸çº¯æ•°æ®è¿›è¡Œæ¸…æ´—
    2.å¢å¤§è®­ç»ƒé›†æ•°æ®é‡
    3.æ­£åˆ™åŒ–ï¼Œå‡å°‘å¼‚å¸¸ç‰¹å¾å½±å“ æˆ– å¯¹å¤æ‚åº¦å½±å“å¤§çš„ç‰¹å¾ çš„å½±å“ -> åœ¨æŸå¤±å‡½æ•°ä¸­æ·»åŠ æ­£åˆ™åŒ–é¡¹
    4.å‡å°‘ç‰¹å¾ç»´åº¦ï¼Œé˜²æ­¢ç»´åº¦ç¾éš¾ï¼šç‰¹å¾å¤šã€æ ·æœ¬å°‘ï¼Œå¯¼è‡´å­¦ä¹ ä¸å……åˆ†ï¼Œæ³›åŒ–èƒ½åŠ›å·®ï¼Œ

L1 L2 æ­£åˆ™åŒ–ï¼š
    ä»‹ç»ï¼šåŸºäºæƒ©ç½šç³»æ•°ä¿®æ”¹ç‰¹å¾åˆ—æƒé‡ï¼Œæƒ©ç½šç³»æ•°è¶Šå¤§ï¼Œä¿®æ”¹åŠ›åº¦è¶Šå¤§ï¼Œå¯¹åº”æƒé‡è¶Šå°
    L1 è¿›è¡Œç‰¹å¾é€‰å–ï¼Œå°†é«˜ç»´ç‰¹å¾æƒé‡ç½®0ï¼Œè¿‡æ»¤æ‰å¯¼è‡´æ¨¡å‹è¿‡æ‹Ÿåˆçš„å°æƒé‡
    L2 è¿›è¡Œç³»æ•°æ”¶ç¼©ï¼Œä½¿æƒé‡è¶‹è¿‘0ï¼Œå¹³å‡åˆ†é…æƒé‡ï¼Œé˜²æ­¢å¤šé‡å…±çº¿æ€§ï¼Œå®é™…å¼€å‘ä¸­åœ¨æ­£ç¡®ç‰¹å¾é€‰å–åä½¿ç”¨L2æ­£åˆ™åŒ–
    ç”ŸåŠ¨å½¢è±¡ï¼š
        å¤¯å“¥å»çˆ¬å±±ï¼Œå¸¦äº†ä¸ªåŒ…ï¼Œè£…äº† å……ç”µå® æ°´ é›¨ä¼ é‹å­ è¡£æœ é¢åŒ…
        L1ï¼šä¸¢æ‰ä¸å¿…è¦çš„ -> å¦‚æœå½“å¤©å»å½“å¤©å›ä¸”å¤©æ°”æ™´æœ— -> ä¸å¸¦é›¨ä¼é‹å­ -> æƒé‡ç½®é›¶
        L2ï¼šæ¢ä¸ªå¤§åŒ… -> ä¸œè¥¿æ²¡å˜ï¼Œç©ºé—´å æ¯”å°äº† -> æƒé‡å˜å°

"""

from sklearn.metrics import mean_squared_error,mean_absolute_error
from sklearn.linear_model import LinearRegression # çº¿æ€§å›å½’æ¢¯åº¦ä¸‹é™æ³•
from sklearn.model_selection import train_test_split
from sklearn.linear_model import Ridge,RidgeCV,Lasso # æ­£åˆ™åŒ–
import numpy as np
import matplotlib.pyplot as plt

# 1. å®šä¹‰å‡½æ•°æ¼”ç¤ºæ¬ æ‹Ÿåˆ
def under_fitting():
    # 1.1 å›ºå®šéšæœºç§å­
    np.random.seed(114)
    # 1.2 ç”Ÿæˆç‰¹å¾æ ‡ç­¾æ•°æ®
    x = np.random.uniform(-3,3,size=100) # ç”Ÿæˆä¸€ç»´æ•°ç»„ï¼Œ100ä¸ªå€¼
    X = x.reshape(-1,1) # é‡æ„æˆ100è¡Œ1åˆ—çš„äºŒç»´æ•°ç»„
    y = 0.5 * x ** 3 + x + np.random.normal(0,1,size=100) # ç”¨çº¿æ€§æ–¹ç¨‹æ‹Ÿåˆä¸€ä¸ªäºŒæ¬¡æ–¹ç¨‹
    # 1.3 è®­ç»ƒæ¨¡å‹
    estimator = LinearRegression()
    estimator.fit(X,y)
    # 1.4 æ¨¡å‹é¢„æµ‹
    pre_result = estimator.predict(X)
    # 1.5 æ¨¡å‹è¯„ä¼°
    print(f'æƒé‡ï¼š{estimator.coef_}')
    print(f'åç½®ï¼š{estimator.intercept_}')
    print(f"MSEï¼š{mean_squared_error(y,pre_result)}")
    print(f"MAEï¼š{mean_absolute_error(y,pre_result)}")
    print(f"RMSEï¼š{np.sqrt(mean_squared_error(y,pre_result))}")
    # 1.6 å¯è§†åŒ–
    plt.figure()
    plt.plot(x,pre_result,color='red')
    plt.scatter(x,y)
    plt.show()

# 2. å®šä¹‰å‡½æ•°æ¼”ç¤ºè¿‡æ‹Ÿåˆ
def over_fitting():
    # 2.1 å›ºå®šéšæœºç§å­
    np.random.seed(23)
    # 2.2 ç”Ÿæˆç‰¹å¾æ ‡ç­¾æ•°æ®
    x = np.random.uniform(-3,3,size=100)    # ç”Ÿæˆä¸€ç»´æ•°ç»„ï¼Œ100ä¸ªå€¼
    X = x.reshape(-1,1)                          # é‡æ„æˆ100è¡Œ1åˆ—çš„äºŒç»´æ•°ç»„
    y = 0.5 * x ** 2 + x + np.random.normal(0,1,size=100) # ç”¨çº¿æ€§æ–¹ç¨‹æ‹Ÿåˆä¸€ä¸ªäºŒæ¬¡æ–¹ç¨‹
    # 2.3 å¢åŠ æ›´å¤šæ¨¡å‹ç‰¹å¾åˆ—ï¼Œå¢åŠ æ¨¡å‹å¤æ‚åº¦,è¾¾åˆ°è¿‡æ‹Ÿåˆæ•ˆæœ ğŸ‘‰ï¼ˆå…¶å®æ˜¯ä¸€ç§ç‰¹å¾å·¥ç¨‹ï¼ŒæŒ–æ˜ç‰¹å¾ä¹‹é—´çš„è”ç³»ï¼Œæ•è·æ›´å¤šç‰¹å¾ï¼‰
    X3 = np.hstack([X,X**2,X**3,X**4,X**5,X**6,X**7,X**8,X**9]) # è¡Œstackï¼Œå°†nä¸ª ğŸ‘‰æ•°ç»„ğŸ‘ˆ è¿›è¡Œæ°´å¹³æ‹¼æ¥ï¼Œæ‹¼æ¥åæ•°ç»„åˆ—æ•°ç­‰äºnï¼Œè¡Œæ•°ä¸å˜
    print(X,X3,sep='\n')
    # 2.4 è®­ç»ƒæ¨¡å‹
    estimator = LinearRegression()
    estimator.fit(X3,y)
    # 2.5 æ¨¡å‹é¢„æµ‹
    pre_result = estimator.predict(X3)
    # 2.6 æ¨¡å‹è¯„ä¼°
    print(f'æƒé‡ï¼š{estimator.coef_}')
    print(f'åç½®ï¼š{estimator.intercept_}')
    print(f"MSEï¼š{mean_squared_error(y,pre_result)}")
    print(f"MAEï¼š{mean_absolute_error(y,pre_result)}")
    print(f"RMSEï¼š{np.sqrt(mean_squared_error(y,pre_result))}")
    # 2.7 å¯è§†åŒ–
    plt.figure()  # np.sort(x)ï¼šå°†åŸå§‹ç‰¹å¾å€¼æŒ‰ä»å°åˆ°å¤§çš„é¡ºåºæ’åˆ—
                  # np.argsort(x)ï¼šè·å–æ’åºåçš„ç´¢å¼•åºåˆ—
    plt.plot(np.sort(x),pre_result[np.argsort(x)],color='red')  # è¿™æ˜¯ä¸€ç§å•å˜é‡é—®é¢˜ä¸“ç”¨å¯è§†åŒ–ï¼Œä»…é€‚åˆå•é©±åŠ¨å› ç´ çš„å¯è§†åŒ–
    plt.scatter(x,y)
    plt.show()
# 3. æ­£å¥½æ‹Ÿåˆ
def just_fitting():
    # 3.1 å›ºå®šéšæœºç§å­
    np.random.seed(23)
    # 3.2 ç”Ÿæˆç‰¹å¾æ ‡ç­¾æ•°æ®
    x = np.random.uniform(-3,3,size=100)    # ç”Ÿæˆä¸€ç»´æ•°ç»„ï¼Œ100ä¸ªå€¼
    X = x.reshape(-1,1)                          # é‡æ„æˆ100è¡Œ1åˆ—çš„äºŒç»´æ•°ç»„
    y = 0.5 * x ** 2 + x + np.random.normal(0,1,size=100) # ç”¨çº¿æ€§æ–¹ç¨‹æ‹Ÿåˆä¸€ä¸ªäºŒæ¬¡æ–¹ç¨‹
    # 3.3 å¢åŠ æ¨¡å‹ç‰¹å¾åˆ—ï¼Œå¢åŠ æ¨¡å‹å¤æ‚åº¦ ğŸ‘‰ï¼ˆå…¶å®æ˜¯ä¸€ç§ç‰¹å¾å·¥ç¨‹ï¼ŒæŒ–æ˜ç‰¹å¾ä¹‹é—´çš„è”ç³»ï¼Œæ•è·æ›´å¤šç‰¹å¾ï¼‰
    X3 = np.hstack([X,X ** 2]) # è¡Œstackï¼Œå°†nä¸ª ğŸ‘‰æ•°ç»„ğŸ‘ˆ è¿›è¡Œæ°´å¹³æ‹¼æ¥ï¼Œæ‹¼æ¥åæ•°ç»„åˆ—æ•°ç­‰äºnï¼Œè¡Œæ•°ä¸å˜
    print(X,X3,sep='\n')
    # 3.4 è®­ç»ƒæ¨¡å‹
    estimator = LinearRegression()
    estimator.fit(X3,y)
    # 3.5 æ¨¡å‹é¢„æµ‹
    pre_result = estimator.predict(X3)
    # 3.6 æ¨¡å‹è¯„ä¼°
    print(f'æƒé‡ï¼š{estimator.coef_}')
    print(f'åç½®ï¼š{estimator.intercept_}')
    print(f"MSEï¼š{mean_squared_error(y,pre_result)}")
    print(f"MAEï¼š{mean_absolute_error(y,pre_result)}")
    print(f"RMSEï¼š{np.sqrt(mean_squared_error(y,pre_result))}")
    # 3.7 å¯è§†åŒ–
    plt.figure()  # np.sort(x)ï¼šå°†åŸå§‹ç‰¹å¾å€¼æŒ‰ä»å°åˆ°å¤§çš„é¡ºåºæ’åˆ—
                  # np.argsort(x)ï¼šè·å–æ’åºåçš„ç´¢å¼•åºåˆ—
    plt.plot(np.sort(x),pre_result[np.argsort(x)],color='red')  # è¿™æ˜¯ä¸€ç§å•å˜é‡é—®é¢˜ä¸“ç”¨å¯è§†åŒ–ï¼Œä»…é€‚åˆå•é©±åŠ¨å› ç´ çš„å¯è§†åŒ–
    plt.scatter(x,y)
    plt.show()
# 4. L1æ­£åˆ™åŒ–
def L1_regularzation():
    # 4.1 å›ºå®šéšæœºç§å­
    np.random.seed(23)
    # 4.2 ç”Ÿæˆç‰¹å¾æ ‡ç­¾æ•°æ®
    x = np.random.uniform(-3, 3, size=100)  # ç”Ÿæˆä¸€ç»´æ•°ç»„ï¼Œ100ä¸ªå€¼
    X = x.reshape(-1, 1)  # é‡æ„æˆ100è¡Œ1åˆ—çš„äºŒç»´æ•°ç»„
    y = 0.5 * x ** 2 + x + np.random.normal(0, 1, size=100)  # ç”¨çº¿æ€§æ–¹ç¨‹æ‹Ÿåˆä¸€ä¸ªäºŒæ¬¡æ–¹ç¨‹
    # 4.3 å¢åŠ æ›´å¤šæ¨¡å‹ç‰¹å¾åˆ—ï¼Œå¢åŠ æ¨¡å‹å¤æ‚åº¦,è¾¾åˆ°è¿‡æ‹Ÿåˆæ•ˆæœ ğŸ‘‰ï¼ˆå…¶å®æ˜¯ä¸€ç§ç‰¹å¾å·¥ç¨‹ï¼ŒæŒ–æ˜ç‰¹å¾ä¹‹é—´çš„è”ç³»ï¼Œæ•è·æ›´å¤šç‰¹å¾ï¼‰
    X3 = np.hstack(
        [X, X ** 2, X ** 3, X ** 4, X ** 5, X ** 6, X ** 7, X ** 8, X ** 9, X ** 10])  # è¡Œstackï¼Œå°†nä¸ª ğŸ‘‰æ•°ç»„ğŸ‘ˆ è¿›è¡Œæ°´å¹³æ‹¼æ¥ï¼Œæ‹¼æ¥åæ•°ç»„åˆ—æ•°ç­‰äºnï¼Œè¡Œæ•°ä¸å˜
    print(X, X3, sep='\n')
    # 4.4 è®­ç»ƒæ¨¡å‹ æ¨¡å‹é€‰å–æ­£åˆ™åŒ–Lassoå¯¹è±¡
    estimator = Lasso(alpha=1.0) #Lassoæ¨¡å‹ä½¿ç”¨åæ ‡ä¸‹é™ï¼Œä¸éœ€è¦è®¾ç½®å­¦ä¹ ç‡ä»€ä¹ˆçš„ï¼Œå¤§æ•°æ®é›†å¯ä»¥æ‰‹åŠ¨è®¾ç½®SGDRegressor+L1æ­£åˆ™åŒ–
    estimator.fit(X3, y)
    # 4.5 æ¨¡å‹é¢„æµ‹
    pre_result = estimator.predict(X3)
    # 4.6 æ¨¡å‹è¯„ä¼°
    print(f'æƒé‡ï¼š{estimator.coef_}')
    print(f'åç½®ï¼š{estimator.intercept_}')
    print(f"MSEï¼š{mean_squared_error(y, pre_result)}")
    print(f"MAEï¼š{mean_absolute_error(y, pre_result)}")
    print(f"RMSEï¼š{np.sqrt(mean_squared_error(y, pre_result))}")
    # 4.7 å¯è§†åŒ–
    plt.figure()  # np.sort(x)ï¼šå°†åŸå§‹ç‰¹å¾å€¼æŒ‰ä»å°åˆ°å¤§çš„é¡ºåºæ’åˆ—
    # np.argsort(x)ï¼šè·å–æ’åºåçš„ç´¢å¼•åºåˆ—
    plt.plot(np.sort(x), pre_result[np.argsort(x)], color='red')  # è¿™æ˜¯ä¸€ç§å•å˜é‡é—®é¢˜ä¸“ç”¨å¯è§†åŒ–ï¼Œä»…é€‚åˆå•é©±åŠ¨å› ç´ çš„å¯è§†åŒ–
    plt.scatter(x, y)
    plt.show()

# 5. L2æ­£åˆ™åŒ–
def L2_regularzation():
    # 5.1 å›ºå®šéšæœºç§å­
    np.random.seed(23)
    # 5.2 ç”Ÿæˆç‰¹å¾æ ‡ç­¾æ•°æ®
    x = np.random.uniform(-3, 3, size=100)  # ç”Ÿæˆä¸€ç»´æ•°ç»„ï¼Œ100ä¸ªå€¼
    X = x.reshape(-1, 1)  # é‡æ„æˆ100è¡Œ1åˆ—çš„äºŒç»´æ•°ç»„
    y = 0.5 * x ** 2 + x + np.random.normal(0, 1, size=100)  # ç”¨çº¿æ€§æ–¹ç¨‹æ‹Ÿåˆä¸€ä¸ªäºŒæ¬¡æ–¹ç¨‹
    # 5.3 å¢åŠ æ›´å¤šæ¨¡å‹ç‰¹å¾åˆ—ï¼Œå¢åŠ æ¨¡å‹å¤æ‚åº¦,è¾¾åˆ°è¿‡æ‹Ÿåˆæ•ˆæœ ğŸ‘‰ï¼ˆå…¶å®æ˜¯ä¸€ç§ç‰¹å¾å·¥ç¨‹ï¼ŒæŒ–æ˜ç‰¹å¾ä¹‹é—´çš„è”ç³»ï¼Œæ•è·æ›´å¤šç‰¹å¾ï¼‰
    X3 = np.hstack(
        [X, X ** 2, X ** 3, X ** 4, X ** 5, X ** 6, X ** 7, X ** 8, X ** 9,
         X ** 10])  # è¡Œstackï¼Œå°†nä¸ª ğŸ‘‰æ•°ç»„ğŸ‘ˆ è¿›è¡Œæ°´å¹³æ‹¼æ¥ï¼Œæ‹¼æ¥åæ•°ç»„åˆ—æ•°ç­‰äºnï¼Œè¡Œæ•°ä¸å˜
    print(X, X3, sep='\n')
    # 5.4 è®­ç»ƒæ¨¡å‹ æ¨¡å‹é€‰å–æ­£åˆ™åŒ–Lassoå¯¹è±¡
    estimator = Ridge(alpha=100.0)
    estimator.fit(X3, y)
    # 5.5 æ¨¡å‹é¢„æµ‹
    pre_result = estimator.predict(X3)
    # 5.6 æ¨¡å‹è¯„ä¼°
    print(f'æƒé‡ï¼š{estimator.coef_}')
    print(f'åç½®ï¼š{estimator.intercept_}')
    print(f"MSEï¼š{mean_squared_error(y, pre_result)}")
    print(f"MAEï¼š{mean_absolute_error(y, pre_result)}")
    print(f"RMSEï¼š{np.sqrt(mean_squared_error(y, pre_result))}")
    # 5.7 å¯è§†åŒ–
    plt.figure()  # np.sort(x)ï¼šå°†åŸå§‹ç‰¹å¾å€¼æŒ‰ä»å°åˆ°å¤§çš„é¡ºåºæ’åˆ—
    # np.argsort(x)ï¼šè·å–æ’åºåçš„ç´¢å¼•åºåˆ—
    plt.plot(np.sort(x), pre_result[np.argsort(x)], color='red')  # è¿™æ˜¯ä¸€ç§å•å˜é‡é—®é¢˜ä¸“ç”¨å¯è§†åŒ–ï¼Œä»…é€‚åˆå•é©±åŠ¨å› ç´ çš„å¯è§†åŒ–
    plt.scatter(x, y)
    plt.show()


if __name__ == '__main__':
    # under_fitting()
    just_fitting()
    # over_fitting()
    # L1_regularzation()
    # L2_regularzation()
